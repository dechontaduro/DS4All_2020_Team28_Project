{
 "cells": [
  {
   "attachments": {
    "ds4a_colombia.svg": {
     "image/svg+xml": [
      "<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 308.55 47.71"><defs><style>.cls-1{fill:none;}.cls-2{clip-path:url(#clip-path);}.cls-3{fill:#699dd3;}.cls-4{fill:#3a3749;}.cls-5{clip-path:url(#clip-path-2);}.cls-6{fill:#fff;}.cls-7{fill:#ececec;}</style><clipPath id="clip-path" transform="translate(0 0)"><rect class="cls-1" width="308.55" height="47.71"/></clipPath><clipPath id="clip-path-2" transform="translate(0 0)"><rect class="cls-1" width="308.55" height="47.71"/></clipPath></defs><g id="Layer_2" data-name="Layer 2"><g id="Layer_1-2" data-name="Layer 1"><g id="COLOMBIA_MAIN_SANS_TAG" data-name="COLOMBIA MAIN SANS TAG"><g class="cls-2"><rect class="cls-3" x="26.67" width="43.54" height="47.71"/><rect class="cls-4" x="73.39" width="235.16" height="47.71"/><g class="cls-5"><path class="cls-4" d="M19.67,4.51a2.81,2.81,0,0,1-5.61-.11,2.81,2.81,0,0,1,5.61.11" transform="translate(0 0)"/><path class="cls-4" d="M12.78,12.33A2.8,2.8,0,1,1,10,9.53a2.79,2.79,0,0,1,2.75,2.8" transform="translate(0 0)"/><path class="cls-4" d="M5.61,20.42A2.79,2.79,0,0,1,2.75,23.1a2.74,2.74,0,1,1,.11-5.48,2.77,2.77,0,0,1,2.75,2.8" transform="translate(0 0)"/><path class="cls-6" d="M35.29,8.69l5.17,0A11.69,11.69,0,0,1,43.32,9a7.54,7.54,0,0,1,2.6,1.15,6.06,6.06,0,0,1,1.89,2.12,6.77,6.77,0,0,1,.75,3.28,6.44,6.44,0,0,1-.69,3.14A6.55,6.55,0,0,1,46,20.84a8,8,0,0,1-2.58,1.27,10.94,10.94,0,0,1-2.86.42l-5.16,0Zm4.85,11.69a9.86,9.86,0,0,0,2-.24A5.55,5.55,0,0,0,44,19.36a4.27,4.27,0,0,0,1.32-1.47,4.72,4.72,0,0,0,.49-2.34,5.08,5.08,0,0,0-.53-2.43,4.12,4.12,0,0,0-1.34-1.46A5.14,5.14,0,0,0,42.08,11a11.41,11.41,0,0,0-2-.18l-2.15,0,.07,9.6Z" transform="translate(0 0)"/><path class="cls-6" d="M57.77,11.61a3.11,3.11,0,0,0-1.15-.83,3.45,3.45,0,0,0-1.49-.32,3.87,3.87,0,0,0-.89.11,2.7,2.7,0,0,0-.8.33,1.92,1.92,0,0,0-.59.58,1.66,1.66,0,0,0,0,1.65,1.87,1.87,0,0,0,.56.56,4,4,0,0,0,.86.39c.34.12.71.23,1.12.34s.93.3,1.42.47a5.56,5.56,0,0,1,1.37.71,3.7,3.7,0,0,1,1,1.1,3.31,3.31,0,0,1,.4,1.68,4.05,4.05,0,0,1-.41,1.92,3.81,3.81,0,0,1-1.12,1.36,4.73,4.73,0,0,1-1.65.82,7.21,7.21,0,0,1-2,.29,7.85,7.85,0,0,1-2.73-.47,5.25,5.25,0,0,1-2.19-1.44l1.8-1.63a3.73,3.73,0,0,0,1.42,1.09,4.25,4.25,0,0,0,1.73.39,4.18,4.18,0,0,0,.91-.11,2.51,2.51,0,0,0,.83-.37,2,2,0,0,0,.6-.63,1.69,1.69,0,0,0,.23-.93,1.52,1.52,0,0,0-.27-.9,2.51,2.51,0,0,0-.71-.61A5,5,0,0,0,55,16.72l-1.28-.4a11,11,0,0,1-1.29-.45,4.6,4.6,0,0,1-1.17-.7,3.52,3.52,0,0,1-.85-1.09,3.45,3.45,0,0,1-.33-1.6,3.48,3.48,0,0,1,.43-1.8,3.94,3.94,0,0,1,1.19-1.25,5.28,5.28,0,0,1,1.67-.74,7.65,7.65,0,0,1,1.91-.26,7.54,7.54,0,0,1,2.21.35,5.45,5.45,0,0,1,2,1.09Z" transform="translate(0 0)"/><path class="cls-6" d="M53.58,24.69l2.35,0,6.69,14.49-3.1,0-1.45-3.31-6.62.05L50.1,39.25l-3,0Zm3.52,9-2.4-5.9-2.34,5.93Z" transform="translate(0 0)"/><path class="cls-6" d="M41.58,36.25H34.26V34.07L41,24.7h3.22v9.43h2.22v2.12H44.21v3H41.58Zm0-8.65h0L37,34.13h4.55Z" transform="translate(0 0)"/><path class="cls-7" d="M101.21,30.66a4.51,4.51,0,0,1-2.34.57,4.73,4.73,0,0,1-2.43-.63,5.39,5.39,0,0,1-1.81-1.75,8.81,8.81,0,0,1-1.13-2.64,13.24,13.24,0,0,1-.39-3.31,13,13,0,0,1,.4-3.33,8.61,8.61,0,0,1,1.15-2.64,5.65,5.65,0,0,1,1.81-1.74,4.68,4.68,0,0,1,2.4-.63,5.5,5.5,0,0,1,2.28.47,4.19,4.19,0,0,1,1.69,1.44l-1.28,1.37a3.33,3.33,0,0,0-1.17-1.06A3,3,0,0,0,99,16.43a2.68,2.68,0,0,0-1.63.51,4.08,4.08,0,0,0-1.13,1.4,7.59,7.59,0,0,0-.68,2.05,13.38,13.38,0,0,0-.23,2.51,13.17,13.17,0,0,0,.23,2.49,7.56,7.56,0,0,0,.69,2.06,3.84,3.84,0,0,0,1.16,1.4,2.65,2.65,0,0,0,1.64.52,2.56,2.56,0,0,0,1.5-.45,3.54,3.54,0,0,0,1-1.1l1.24,1.32a4.72,4.72,0,0,1-1.59,1.52" transform="translate(0 0)"/><path class="cls-7" d="M123,22.88a14.38,14.38,0,0,1-.38,3.4,8.34,8.34,0,0,1-1.11,2.64,5.45,5.45,0,0,1-1.74,1.71,4.52,4.52,0,0,1-2.33.6,4.58,4.58,0,0,1-2.34-.6,5.41,5.41,0,0,1-1.76-1.71,8.56,8.56,0,0,1-1.1-2.64,14.38,14.38,0,0,1-.38-3.4,14.43,14.43,0,0,1,.37-3.41,8.16,8.16,0,0,1,1.08-2.63A5.1,5.1,0,0,1,115,15.16a4.7,4.7,0,0,1,2.38-.6,4.52,4.52,0,0,1,2.33.6,5.25,5.25,0,0,1,1.74,1.68,8.18,8.18,0,0,1,1.11,2.63,14.41,14.41,0,0,1,.38,3.41m-2.18,0a14.56,14.56,0,0,0-.22-2.54,7.88,7.88,0,0,0-.65-2.07,3.94,3.94,0,0,0-1-1.38,2.26,2.26,0,0,0-1.46-.51,2.32,2.32,0,0,0-1.49.51,3.87,3.87,0,0,0-1.07,1.38,7.89,7.89,0,0,0-.63,2.07,15.41,15.41,0,0,0,0,5.07,7.89,7.89,0,0,0,.63,2.07,3.78,3.78,0,0,0,1.07,1.38,2.32,2.32,0,0,0,1.49.51,2.26,2.26,0,0,0,1.46-.51,3.85,3.85,0,0,0,1-1.38,7.88,7.88,0,0,0,.65-2.07,14.53,14.53,0,0,0,.22-2.53" transform="translate(0 0)"/><polygon class="cls-7" points="133.66 30.85 133.66 14.95 135.72 14.95 135.72 28.96 140.31 28.96 140.31 30.85 133.66 30.85"/><path class="cls-7" d="M159.78,22.88a13.88,13.88,0,0,1-.38,3.4,8.56,8.56,0,0,1-1.1,2.64,5.45,5.45,0,0,1-1.74,1.71,4.84,4.84,0,0,1-4.67,0,5.41,5.41,0,0,1-1.76-1.71,8.56,8.56,0,0,1-1.1-2.64,13.88,13.88,0,0,1-.38-3.4,14.43,14.43,0,0,1,.37-3.41,8.38,8.38,0,0,1,1.07-2.63,5.12,5.12,0,0,1,1.76-1.68,4.7,4.7,0,0,1,2.38-.6,4.52,4.52,0,0,1,2.33.6,5.25,5.25,0,0,1,1.74,1.68,8.4,8.4,0,0,1,1.1,2.63,13.91,13.91,0,0,1,.38,3.41m-2.18,0a13.65,13.65,0,0,0-.22-2.54,7.88,7.88,0,0,0-.64-2.07,3.94,3.94,0,0,0-1.05-1.38,2.28,2.28,0,0,0-1.46-.51,2.3,2.3,0,0,0-1.49.51,3.87,3.87,0,0,0-1.07,1.38,7.21,7.21,0,0,0-.63,2.07,15.41,15.41,0,0,0,0,5.07,7.21,7.21,0,0,0,.63,2.07,3.78,3.78,0,0,0,1.07,1.38,2.3,2.3,0,0,0,1.49.51,2.28,2.28,0,0,0,1.46-.51,3.85,3.85,0,0,0,1.05-1.38,7.88,7.88,0,0,0,.64-2.07,13.62,13.62,0,0,0,.22-2.53" transform="translate(0 0)"/><polygon class="cls-7" points="181.59 30.85 181.59 17.69 181.52 17.69 177.9 30.85 176.04 30.85 172.46 17.69 172.39 17.69 172.39 30.85 170.48 30.85 170.48 14.95 173.52 14.95 176.99 27.57 177.08 27.57 180.49 14.95 183.66 14.95 183.66 30.85 181.59 30.85"/><path class="cls-7" d="M201.06,22.49a3.41,3.41,0,0,1,.93.36,3.08,3.08,0,0,1,.91.76,3.8,3.8,0,0,1,.69,1.19,4.67,4.67,0,0,1,.28,1.67,4.6,4.6,0,0,1-.42,2.07A4,4,0,0,1,201,30.63a5.43,5.43,0,0,1-1.52.22h-4.39V15H199a6.93,6.93,0,0,1,1.46.16,4.05,4.05,0,0,1,1.41.62,3.57,3.57,0,0,1,1.06,1.21,4.13,4.13,0,0,1,.41,1.94,4.69,4.69,0,0,1-.18,1.37,3.73,3.73,0,0,1-.5,1,2.9,2.9,0,0,1-.71.73,3.8,3.8,0,0,1-.84.45Zm.3-3.31a2.75,2.75,0,0,0-.23-1.21,2.13,2.13,0,0,0-1.43-1.22,4,4,0,0,0-1-.12H197v5.14h1.77a3.09,3.09,0,0,0,.93-.14,2.62,2.62,0,0,0,.84-.45,2.32,2.32,0,0,0,.59-.8,2.76,2.76,0,0,0,.23-1.2m.44,7.17a3.38,3.38,0,0,0-.26-1.39,2.87,2.87,0,0,0-.68-.93,2.63,2.63,0,0,0-.93-.5,3.38,3.38,0,0,0-1-.16H197v5.8h2a3.6,3.6,0,0,0,1.09-.17,2.69,2.69,0,0,0,.89-.51,2.26,2.26,0,0,0,.6-.87,3.24,3.24,0,0,0,.22-1.27" transform="translate(0 0)"/><rect class="cls-7" x="214.36" y="14.94" width="2.07" height="15.91"/><path class="cls-7" d="M234.88,30.85,234,27.12h-4.7l-.94,3.73h-2.09L230.31,15h2.74l4,15.9Zm-3.19-14h-.09l-2.07,8.7h4.16Z" transform="translate(0 0)"/></g></g></g></g></g></svg>"
     ]
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ds4a_colombia.svg](attachment:ds4a_colombia.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impacto de la deforestaci√≥n en el regimen de caudales de los rios en Colombia (TEAM 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate time series forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources :\n",
    "\n",
    "https://towardsdatascience.com/vector-autoregressions-vector-error-correction-multivariate-model-a69daf6ab618\n",
    "\n",
    "https://towardsdatascience.com/pairs-trading-with-cryptocurrencies-e79b4a00b015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(num = None, figsize = (15, 12), dpi = 80, facecolor = 'w', edgecolor = 'k')\n",
    "plt.rcParams.update({'font.size': 16, 'figure.figsize': (15, 10), \n",
    "                     'figure.max_open_warning': 200})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table2lags(table, max_lag, min_lag=0, separator='_'):\n",
    "    \"\"\" Given a dataframe, return a dataframe with different lags of all its columns \"\"\"\n",
    "    values=[]\n",
    "    for i in range(min_lag, max_lag + 1):\n",
    "        values.append(table.shift(i).copy())\n",
    "        values[-1].columns = [c + separator + str(i) for c in table.columns]\n",
    "    return pd.concat(values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt.rcParams.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macrodata = pd.read_csv('../data/matrix/matrix_consol_v2.zip')\n",
    "\n",
    "macrodata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_stationary = pd.read_csv('../model/mc_stationary.csv')\n",
    "\n",
    "is_stationary.fillna(value = 0, inplace = True)\n",
    "\n",
    "is_stationary = is_stationary.astype('int')\n",
    "\n",
    "is_stationary.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcs = macrodata['mc'].unique()\n",
    "mcs.sort()\n",
    "\n",
    "print(mcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.DataFrame(pd.date_range('2018-01-01','2019-12-31' , freq='1M') - \n",
    "             pd.offsets.MonthBegin(1))\n",
    "dates.columns = ['date']\n",
    "\n",
    "dates['year'] = pd.DatetimeIndex(dates['date']).year\n",
    "dates['month'] = pd.DatetimeIndex(dates['date']).month\n",
    "\n",
    "dates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process for all Macro basins (Version 1 : Without hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobs = 24 # 24 meses para test\n",
    "\n",
    "RFR_metrics = pd.DataFrame()\n",
    "RFR_prediction = pd.DataFrame()\n",
    "\n",
    "for i in mcs:\n",
    "    \n",
    "    print('\\n==================================================================')\n",
    "    print('MC = %s' % i)\n",
    "    print('====================================================================\\n')\n",
    "    \n",
    "    temp_df = macrodata[macrodata['mc'] == i].copy().reset_index(drop = True)\n",
    "    temp_df['v_loss_cover_10k'] = temp_df['v_loss_cover'] * 10000\n",
    "    X = table2lags(temp_df[['v_loss_cover_10k', 'v_rainfall_total']], 2)\n",
    "    X.fillna(0.00, inplace=True)\n",
    "\n",
    "    X_train = X.iloc[0:-nobs].reset_index(drop = True)\n",
    "    y_train = temp_df[0:-nobs]['v_flow_mean'].reset_index(drop = True)\n",
    "\n",
    "    X_test = X.iloc[-nobs:].reset_index(drop = True)\n",
    "    X_test_org = temp_df.iloc[-nobs:].reset_index(drop = True)\n",
    "    y_test = temp_df[-nobs:]['v_flow_mean'].reset_index(drop = True)\n",
    "\n",
    "#     print('\\n== X train ==========================================================')\n",
    "#     print(X_train.head())\n",
    "#     print('\\n== y train ==========================================================')\n",
    "#     print(y_train.head())\n",
    "#     print('\\n== X test ==========================================================')\n",
    "#     print(X_test.head())\n",
    "#     print('\\n== y test ==========================================================')\n",
    "#     print(y_test.head())\n",
    "#     print('=====================================================================\\n')\n",
    "    \n",
    "    rfR = RandomForestRegressor(n_estimators = 200, max_depth = 100, criterion = 'mse', \n",
    "                                random_state = 42, verbose = 0, \n",
    "                                n_jobs = 5).fit(X_train, y_train)\n",
    "    \n",
    "#     print(rfR)\n",
    "    \n",
    "    rfR.score(X_test,y_test)\n",
    "\n",
    "    df_forecast = pd.DataFrame({'v_flow_mean_mean': rfR.predict(X_test)})\n",
    "    df_forecast.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    df_forecast = pd.concat([y_test, df_forecast], axis = 1)\n",
    "    df_forecast.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    forecast_errors = [df_forecast.v_flow_mean.iloc[j] - df_forecast.v_flow_mean_mean.iloc[j] \n",
    "                       for j in range(nobs)]\n",
    "    bias = sum(forecast_errors) * 1.0 / (nobs)\n",
    "#     print('Bias : %f' % bias)\n",
    "\n",
    "    mae = skm.mean_absolute_error(df_forecast.v_flow_mean, df_forecast.v_flow_mean_mean)\n",
    "#     print('MAE : %f' % mae)\n",
    "\n",
    "    mse = skm.mean_squared_error(df_forecast.v_flow_mean, df_forecast.v_flow_mean_mean)\n",
    "    rmse = np.sqrt(mse)\n",
    "#     print('MSE : %f' % mse)\n",
    "#     print('RMSE : %f' % rmse) \n",
    "    \n",
    "    X_test_org.drop(columns = ['v_flow_mean'], inplace = True)\n",
    "    \n",
    "    df_forecast = pd.concat([X_test_org, df_forecast], axis = 1)\n",
    "    df_forecast.drop(columns = ['v_temperature_mean', 'v_loss_cover_10k'], inplace = True)\n",
    "    df_forecast.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    df_forecast = df_forecast[['date', 'year', 'month', 'mc', 'v_flow_mean_mean', \n",
    "                               'v_flow_mean', 'v_loss_cover', 'v_rainfall_total']]\n",
    "\n",
    "    print('\\n== y predict =======================================================')\n",
    "    print(df_forecast.head())\n",
    "    print('=====================================================================\\n')\n",
    "    \n",
    "    metrics = [i, bias, mae, mse, rmse]\n",
    "    metrics = pd.DataFrame([metrics], columns = ['mc', 'Bias', 'MAE', 'MSE', 'RMSE'])\n",
    "    \n",
    "    print('\\n== Metrics =======================================================')\n",
    "    print(metrics.head())\n",
    "    print('==================================================================\\n')\n",
    "    \n",
    "    RFR_metrics = pd.concat([RFR_metrics, metrics], axis = 0)\n",
    "    RFR_prediction = pd.concat([RFR_prediction, df_forecast], axis = 0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR_metrics.to_csv('../model/RFR_results_v1.csv', index = False)\n",
    "RFR_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR_prediction['v_flow_mean_mean'] = RFR_prediction['v_flow_mean_mean'].apply(lambda x: \n",
    "                                                                              0.01 if x <= 0 \n",
    "                                                                              else x)\n",
    "RFR_prediction.to_csv('../model/RFR_predictions_v1.csv', index = False)\n",
    "\n",
    "RFR_prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process for all Macro basins (Version 1 : Without hyperparameter tuning - Prediction 2020 2021 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read scenarios for independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = pd.read_excel('../data/matrix/Esc_Predicciones_longitudinal.xlsx')\n",
    "\n",
    "scenarios['v_flow_mean'] = 0\n",
    "\n",
    "scenarios = scenarios[['date', 'mc', 'v_flow_mean', 'v_loss_cover', 'v_rainfall_total', \n",
    "                       'scenario']]\n",
    "\n",
    "scenarios.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.DataFrame(pd.date_range('2020-01-01','2021-12-31' , freq='1M') - \n",
    "             pd.offsets.MonthBegin(1))\n",
    "dates.columns = ['date']\n",
    "\n",
    "dates['year'] = pd.DatetimeIndex(dates['date']).year\n",
    "dates['month'] = pd.DatetimeIndex(dates['date']).month\n",
    "\n",
    "dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "escen = scenarios['scenario'].unique()\n",
    "\n",
    "nobs = 24 # 24 meses para test\n",
    "\n",
    "RFR_prediction = pd.DataFrame()\n",
    "\n",
    "for j in escen:\n",
    "   \n",
    "    print('Escenario :', j, '\\n')\n",
    "    \n",
    "    data_test_predict = scenarios[scenarios['scenario'] == j]\n",
    "\n",
    "    for i in mcs:\n",
    "    \n",
    "        print('\\n==================================================================')\n",
    "        print('MC = %s' % i)\n",
    "        print('====================================================================\\n')\n",
    "\n",
    "        temp_df = macrodata[macrodata['mc'] == i].copy().reset_index(drop = True)\n",
    "        temp_df['v_loss_cover_10k'] = temp_df['v_loss_cover'] * 10000\n",
    "       \n",
    "        X = table2lags(temp_df[['v_loss_cover_10k', 'v_rainfall_total']], 2)\n",
    "        X.fillna(0.00, inplace=True)\n",
    "\n",
    "        X_train = X.reset_index(drop = True)\n",
    "        y_train = temp_df['v_flow_mean'].reset_index(drop = True)\n",
    "\n",
    "        X_test = data_test_predict[data_test_predict['mc'] == i].reset_index(drop = True)\n",
    "        X_test['v_loss_cover_10k'] = X_test['v_loss_cover'] * 10000\n",
    "        y_test = X_test['v_flow_mean'].reset_index(drop = True)\n",
    "        \n",
    "        # =======================================================================\n",
    "        # Generamos la variable v_rainfall_total de manera aleatoria para pruebas\n",
    "        # =======================================================================\n",
    "#         X_test['v_rainfall_total'] = np.around(\n",
    "#             np.random.uniform(X_test['v_rainfall_total'].min(), \n",
    "#                               X_test['v_rainfall_total'].max(), size = nobs),4)\n",
    "#         print(X_test['v_rainfall_total'].min(), X_test['v_rainfall_total'].max())\n",
    "        # =======================================================================\n",
    "        \n",
    "        X_test_org = X_test\n",
    "                \n",
    "        X_test = table2lags(X_test[['v_loss_cover_10k', 'v_rainfall_total']], 2)\n",
    "        X_test.fillna(0.00, inplace=True)\n",
    "\n",
    "        rfR = RandomForestRegressor(n_estimators = 200, max_depth = 100, criterion = 'mse', \n",
    "                                    random_state = 42, verbose = 0, \n",
    "                                    n_jobs = 5).fit(X_train, y_train)\n",
    "\n",
    "        rfR.score(X_test,y_test)\n",
    "        \n",
    "        df_forecast = pd.DataFrame({'v_flow_mean_forecast': rfR.predict(X_test)})\n",
    "        df_forecast.reset_index(drop = True, inplace = True)\n",
    "        \n",
    "        df_forecast = pd.concat([X_test_org, df_forecast], axis = 1)\n",
    "        df_forecast.drop(columns = ['v_flow_mean', 'v_loss_cover_10k'], inplace = True)\n",
    "        \n",
    "        RFR_prediction = pd.concat([RFR_prediction, df_forecast], axis = 0)\n",
    "        \n",
    "RFR_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal con valores aleatorios en v_rainfall_total\n",
    "\n",
    "# RFR_prediction['v_flow_mean_forecast'] = RFR_prediction['v_flow_mean_forecast'].apply(lambda x: \n",
    "#                                                                               0.01 if x <= 0 \n",
    "#                                                                               else x)\n",
    "# RFR_prediction.to_csv('../model/RFR_forecast_2020_2021_temp.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFR_prediction['v_flow_mean_forecast'] = RFR_prediction['v_flow_mean_forecast'].apply(lambda x: \n",
    "#                                                                               0.01 if x <= 0 \n",
    "#                                                                               else x)\n",
    "RFR_prediction.to_csv('../model/RFR_forecast_2020_2021.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process for all Macro basins (Version 2 : Without hyperparameter tuning - with stationary treatement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobs = 24 # 24 meses para test\n",
    "\n",
    "RFR_metrics = pd.DataFrame()\n",
    "RFR_prediction = pd.DataFrame()\n",
    "\n",
    "for i in mcs:\n",
    "    \n",
    "    print('\\n==================================================================')\n",
    "    print('MC = %s' % i)\n",
    "    print('====================================================================\\n')\n",
    "    \n",
    "    temp_df = macrodata[macrodata['mc'] == i].copy().reset_index(drop = True)\n",
    "    temp_df['v_loss_cover_10k'] = temp_df['v_loss_cover'] * 10000\n",
    "    X = table2lags(temp_df[['v_loss_cover_10k', 'v_rainfall_total']], 2)\n",
    "    X.fillna(0.00, inplace=True)\n",
    "\n",
    "    X_train = X.iloc[0:-nobs].reset_index(drop = True)\n",
    "    y_train = temp_df[0:-nobs]['v_flow_mean'].reset_index(drop = True)\n",
    "    y_train = np.log(y_train + 0.001)\n",
    "\n",
    "    X_test = X.iloc[-nobs:].reset_index(drop = True)\n",
    "    X_test_org = temp_df.iloc[-nobs:].reset_index(drop = True)\n",
    "    y_test = temp_df[-nobs:]['v_flow_mean'].reset_index(drop = True)\n",
    "    y_test = np.log(y_test + 0.001)\n",
    "\n",
    "#     print('\\n== X train ==========================================================')\n",
    "#     print(X_train.head())\n",
    "#     print('\\n== y train ==========================================================')\n",
    "#     print(y_train.head())\n",
    "#     print('\\n== X test ==========================================================')\n",
    "#     print(X_test.head())\n",
    "#     print('\\n== y test ==========================================================')\n",
    "#     print(y_test.head())\n",
    "#     print('=====================================================================\\n')\n",
    "    \n",
    "    rfR = RandomForestRegressor(n_estimators = 200, max_depth = 100, criterion = 'mse', \n",
    "                                random_state = 42, verbose = 0, \n",
    "                                n_jobs = 5).fit(X_train, y_train)\n",
    "    \n",
    "#     print(rfR)\n",
    "    \n",
    "    rfR.score(X_test,y_test)\n",
    "\n",
    "    df_forecast = pd.DataFrame({'v_flow_mean_mean': rfR.predict(X_test)})\n",
    "    df_forecast.reset_index(drop = True, inplace = True)\n",
    "    df_forecast['v_flow_mean_mean'] = np.exp(df_forecast['v_flow_mean_mean'])\n",
    "\n",
    "    df_forecast = pd.concat([y_test, df_forecast], axis = 1)\n",
    "    df_forecast['v_flow_mean'] = np.exp(df_forecast['v_flow_mean'])\n",
    "    df_forecast.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "#     print(df_forecast.head())\n",
    "    \n",
    "    forecast_errors = [df_forecast.v_flow_mean.iloc[j] - df_forecast.v_flow_mean_mean.iloc[j] \n",
    "                       for j in range(nobs)]\n",
    "    bias = sum(forecast_errors) * 1.0 / (nobs)\n",
    "#     print('Bias : %f' % bias)\n",
    "\n",
    "    mae = skm.mean_absolute_error(df_forecast.v_flow_mean, df_forecast.v_flow_mean_mean)\n",
    "#     print('MAE : %f' % mae)\n",
    "\n",
    "    mse = skm.mean_squared_error(df_forecast.v_flow_mean, df_forecast.v_flow_mean_mean)\n",
    "    rmse = np.sqrt(mse)\n",
    "#     print('MSE : %f' % mse)\n",
    "#     print('RMSE : %f' % rmse) \n",
    "    \n",
    "    X_test_org.drop(columns = ['v_flow_mean'], inplace = True)\n",
    "    \n",
    "    df_forecast = pd.concat([X_test_org, df_forecast], axis = 1)\n",
    "    df_forecast.drop(columns = ['v_temperature_mean', 'v_loss_cover_10k'], inplace = True)\n",
    "    df_forecast.reset_index(drop = True, inplace = True)\n",
    "#     df_forecast.drop(columns = ['v_flow_mean'], inplace = True)\n",
    "\n",
    "    df_forecast = df_forecast[['date', 'year', 'month', 'mc', 'v_flow_mean_mean', \n",
    "                               'v_flow_mean', 'v_loss_cover', 'v_rainfall_total']]\n",
    "\n",
    "    print('\\n== y predict =======================================================')\n",
    "    print(df_forecast.head())\n",
    "    print('=====================================================================\\n')\n",
    "    \n",
    "    metrics = [i, bias, mae, mse, rmse]\n",
    "    metrics = pd.DataFrame([metrics], columns = ['mc', 'Bias', 'MAE', 'MSE', 'RMSE'])\n",
    "    \n",
    "    print('\\n== Metrics =======================================================')\n",
    "    print(metrics.head())\n",
    "    print('==================================================================\\n')\n",
    "    \n",
    "    RFR_metrics = pd.concat([RFR_metrics, metrics], axis = 0)\n",
    "    RFR_prediction = pd.concat([RFR_prediction, df_forecast], axis = 0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR_metrics.to_csv('../model/RFR_results_v2.csv', index = False)\n",
    "RFR_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR_prediction['v_flow_mean_mean'] = RFR_prediction['v_flow_mean_mean'].apply(lambda x: \n",
    "                                                                              0.01 if x <= 0 \n",
    "                                                                              else x)\n",
    "RFR_prediction.to_csv('../model/RFR_predictions_v2.csv', index = False)\n",
    "\n",
    "RFR_prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('ds4a': conda)",
   "language": "python",
   "name": "python38264bitds4acondafc01702769ab4524a15cea8dad87138e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
