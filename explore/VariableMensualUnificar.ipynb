{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "sys.path.insert(0, '../libs')\n",
    "\n",
    "import process_files\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import time\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_files_path = r'../data/variables/var-mes-*-fill.zip'\n",
    "#estation_completitud_path = r'../data/variables_profiles/CUM70_todas.csv'\n",
    "variable_full_output = r'../data/variables/var-mes-todas-fill-union.csv'\n",
    "variable_full_tidy_output = r'../data/variables/var-mes-todas-fill-union-col.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['..\\\\data\\\\variables\\\\var-mes-PTPM_CON-fill.zip', '..\\\\data\\\\variables\\\\var-mes-Q_MEDIA_D-fill.zip', '..\\\\data\\\\variables\\\\var-mes-Q_MN_D-fill.zip', '..\\\\data\\\\variables\\\\var-mes-Q_MX_D-fill.zip', '..\\\\data\\\\variables\\\\var-mes-TMN_CON-fill.zip', '..\\\\data\\\\variables\\\\var-mes-TMX_CON-fill.zip']\n"
     ]
    }
   ],
   "source": [
    "_path = variable_files_path.split('/')\n",
    "_files = glob.glob(os.path.join(*_path))\n",
    "print(_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = { 'CodigoEstacion':'string', 'Etiqueta':'string'}\n",
    "usecols = ['CodigoEstacion', 'Etiqueta', 'Fecha', 'min', 'median', 'max', 'count']\n",
    "#dtypesEstacionesCompletas = { 'codigo':'string'}\n",
    "#usecolsEstacionesCompletas = ['codigo']\n",
    "etiqueta_valor = {'PTPM_CON':['min','median','max', 'count'], \n",
    "                  'Q_MN_D':['min', 'count'],\n",
    "                  'Q_MEDIA_D':['min','median','max','count'],\n",
    "                  'Q_MX_D':['max', 'count'],\n",
    "                  'TMN_CON':['min', 'count'],\n",
    "                  'TMX_CON':['max', 'count']\n",
    "                  }\n",
    "dateparse = lambda x: datetime.strptime(x, '%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#print(f'..... h:{time.asctime()} f:{estation_completitud_path} leyendo completas .....')\n",
    "#dfcom = pd.read_csv(estation_completitud_path, dtype = dtypesEstacionesCompletas)\n",
    "#print(f'----- r:{dfcom.shape} h:{time.asctime()} t:{(time.time() - start_time) / 60} -----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unificar(f):\n",
    "    print(f'##### h:{time.asctime()} f:{f} leyendo #####')\n",
    "    df = pd.read_csv(f, dtype = dtypes, usecols = usecols)\n",
    "    etiqueta = df.iat[0,1]\n",
    "    print(f'----- h:{time.asctime()} t:{(time.time() - start_time) / 60} {etiqueta} {df.shape}-----')\n",
    "    \n",
    "    #print(f'..... h:{time.asctime()} e:{etiqueta} Filtrando completas .....')\n",
    "    #df = df.merge(dfcom, left_on='CodigoEstacion', right_on='codigo', how = 'inner' )\n",
    "    #df.drop('codigo', axis = 'columns', inplace = True)\n",
    "    df.columns = ['codigo', 'etiqueta', 'fecha', 'min', 'median', 'max', 'count']\n",
    "    #print(f'----- h:{time.asctime()} t:{(time.time() - start_time) / 60} {df.shape} -----')\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    for valor in etiqueta_valor[etiqueta]:\n",
    "        print(f'..... h:{time.asctime()} v:{valor} creando df .....')\n",
    "        dfc = df[['codigo', 'etiqueta', 'fecha', valor]].copy()\n",
    "        dfc['etiqueta'] = dfc['etiqueta'] + '_' + valor\n",
    "        dfc.columns = ['codigo', 'etiqueta', 'fecha', 'valor']\n",
    "        dfs.append(dfc)\n",
    "        print(f'----- h:{time.asctime()} t:{(time.time() - start_time) / 60} {dfc.shape} -----')\n",
    "    \n",
    "    dfs = pd.concat(dfs, axis = 0)\n",
    "    print(f'***** h:{time.asctime()} t:{(time.time() - start_time) / 60} {dfs.shape} *****')\n",
    "    \n",
    "    return dfs\n",
    "    #return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['..\\\\data\\\\variables\\\\var-mes-PTPM_CON-fill.zip', '..\\\\data\\\\variables\\\\var-mes-Q_MEDIA_D-fill.zip', '..\\\\data\\\\variables\\\\var-mes-Q_MN_D-fill.zip', '..\\\\data\\\\variables\\\\var-mes-Q_MX_D-fill.zip', '..\\\\data\\\\variables\\\\var-mes-TMN_CON-fill.zip', '..\\\\data\\\\variables\\\\var-mes-TMX_CON-fill.zip']\n",
      "##### h:Sun Jul 26 18:39:53 2020 f:..\\data\\variables\\var-mes-PTPM_CON-fill.zip leyendo #####\n",
      "----- h:Sun Jul 26 18:39:57 2020 t:0.11188269853591919 PTPM_CON (614220, 7)-----\n",
      "..... h:Sun Jul 26 18:39:57 2020 v:min creando df .....\n",
      "----- h:Sun Jul 26 18:39:58 2020 t:0.11776609818140665 (614220, 4) -----\n",
      "..... h:Sun Jul 26 18:39:58 2020 v:median creando df .....\n",
      "----- h:Sun Jul 26 18:39:58 2020 t:0.12388273477554321 (614220, 4) -----\n",
      "..... h:Sun Jul 26 18:39:58 2020 v:max creando df .....\n",
      "----- h:Sun Jul 26 18:39:58 2020 t:0.12943272988001506 (614220, 4) -----\n",
      "..... h:Sun Jul 26 18:39:58 2020 v:count creando df .....\n",
      "----- h:Sun Jul 26 18:39:59 2020 t:0.1348660429318746 (614220, 4) -----\n",
      "***** h:Sun Jul 26 18:39:59 2020 t:0.1390660802523295 (2456880, 4) *****\n",
      "##### h:Sun Jul 26 18:39:59 2020 f:..\\data\\variables\\var-mes-Q_MEDIA_D-fill.zip leyendo #####\n",
      "----- h:Sun Jul 26 18:40:01 2020 t:0.1715160846710205 Q_MEDIA_D (259102, 7)-----\n",
      "..... h:Sun Jul 26 18:40:01 2020 v:min creando df .....\n",
      "----- h:Sun Jul 26 18:40:01 2020 t:0.1737660845120748 (259102, 4) -----\n",
      "..... h:Sun Jul 26 18:40:01 2020 v:median creando df .....\n",
      "----- h:Sun Jul 26 18:40:01 2020 t:0.17653274536132812 (259102, 4) -----\n",
      "..... h:Sun Jul 26 18:40:01 2020 v:max creando df .....\n",
      "----- h:Sun Jul 26 18:40:01 2020 t:0.17874943415323893 (259102, 4) -----\n",
      "..... h:Sun Jul 26 18:40:01 2020 v:count creando df .....\n",
      "----- h:Sun Jul 26 18:40:01 2020 t:0.18116607666015624 (259102, 4) -----\n",
      "***** h:Sun Jul 26 18:40:02 2020 t:0.1826494018236796 (1036408, 4) *****\n",
      "##### h:Sun Jul 26 18:40:02 2020 f:..\\data\\variables\\var-mes-Q_MN_D-fill.zip leyendo #####\n",
      "----- h:Sun Jul 26 18:40:03 2020 t:0.20419936974843342 Q_MN_D (166263, 7)-----\n",
      "..... h:Sun Jul 26 18:40:03 2020 v:min creando df .....\n",
      "----- h:Sun Jul 26 18:40:03 2020 t:0.20591614643732706 (166263, 4) -----\n",
      "..... h:Sun Jul 26 18:40:03 2020 v:count creando df .....\n",
      "----- h:Sun Jul 26 18:40:03 2020 t:0.20781606038411457 (166263, 4) -----\n",
      "***** h:Sun Jul 26 18:40:03 2020 t:0.20889939467112223 (332526, 4) *****\n",
      "##### h:Sun Jul 26 18:40:03 2020 f:..\\data\\variables\\var-mes-Q_MX_D-fill.zip leyendo #####\n",
      "----- h:Sun Jul 26 18:40:04 2020 t:0.2276160677274068 Q_MX_D (166263, 7)-----\n",
      "..... h:Sun Jul 26 18:40:04 2020 v:max creando df .....\n",
      "----- h:Sun Jul 26 18:40:04 2020 t:0.22939943472544352 (166263, 4) -----\n",
      "..... h:Sun Jul 26 18:40:04 2020 v:count creando df .....\n",
      "----- h:Sun Jul 26 18:40:04 2020 t:0.23106622695922852 (166263, 4) -----\n",
      "***** h:Sun Jul 26 18:40:05 2020 t:0.2316160758336385 (332526, 4) *****\n",
      "##### h:Sun Jul 26 18:40:05 2020 f:..\\data\\variables\\var-mes-TMN_CON-fill.zip leyendo #####\n",
      "----- h:Sun Jul 26 18:40:05 2020 t:0.246299413839976 TMN_CON (141906, 7)-----\n",
      "..... h:Sun Jul 26 18:40:05 2020 v:min creando df .....\n",
      "----- h:Sun Jul 26 18:40:05 2020 t:0.24796610275904338 (141906, 4) -----\n",
      "..... h:Sun Jul 26 18:40:05 2020 v:count creando df .....\n",
      "----- h:Sun Jul 26 18:40:06 2020 t:0.24941611289978027 (141906, 4) -----\n",
      "***** h:Sun Jul 26 18:40:06 2020 t:0.24998273849487304 (283812, 4) *****\n",
      "##### h:Sun Jul 26 18:40:06 2020 f:..\\data\\variables\\var-mes-TMX_CON-fill.zip leyendo #####\n",
      "----- h:Sun Jul 26 18:40:07 2020 t:0.26826608180999756 TMX_CON (141906, 7)-----\n",
      "..... h:Sun Jul 26 18:40:07 2020 v:max creando df .....\n",
      "----- h:Sun Jul 26 18:40:07 2020 t:0.2697827776273092 (141906, 4) -----\n",
      "..... h:Sun Jul 26 18:40:07 2020 v:count creando df .....\n",
      "----- h:Sun Jul 26 18:40:07 2020 t:0.2710327744483948 (141906, 4) -----\n",
      "***** h:Sun Jul 26 18:40:07 2020 t:0.27144953012466433 (283812, 4) *****\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = process_files.processFiles(variable_files_path, unificar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 394 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfs = pd.concat([r['result'] for r in res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Almacenar una variable por fila\n",
    "dfs.to_csv(variable_full_output, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfs.set_index(['codigo', 'etiqueta', 'fecha'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#pasar las variables a las columnas\n",
    "dfs = dfs.unstack('etiqueta').reset_index()\n",
    "dfs[dfs.filter(regex='count').columns] = dfs[dfs.filter(regex='count').columns].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfs.to_csv(variable_full_tidy_output, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
